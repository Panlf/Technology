# RabbitMQ消息中间件
## 简述RabbitMQ的架构设计

- Broker：RabbitMQ的服务节点
- Queue：队列，是RabbitMQ的内部对象，用于存储消息。RabbitMQ中消息只能存储在队列中。生产者投递消息到队列，消费者从队列中获取消息并消费。多个消费者可以订阅同一个队列，这时队列中的消息会被平均分摊（轮询）给多个消费者进行消费，而不是每个消费者都收到所有的消息进行消费。（注意：RabbitMQ不支持队列层面的广播消息，如果需要广播消息，可以采用一个交换器通过路由key绑定多个队列，由多个消费者来订阅这些队列的方式）
- Exchange：交换器。生产者将消息发送到Exchange，由交换器将消息路由到一个或多个队列中。如果路由不到，或返回给生产者，或直接丢弃，或做其他处理
- RoutingKey：路由Key。生产者将消息发送给交换器的时候，一般会指定一个RoutingKey，用来指定这个消息的路由规则。这个路由Key需要与交换器类型和绑定键（BindingKey）联合使用才能最终生效。在交换器类型和绑定键固定的情况下，生产者可以在发送消息给交换器时通过指定RoutingKey来决定消息流向哪里。
- Binding：通过绑定将交换器和队列关联起来，在绑定的时候一般会指定一个绑定建，这样RabbitMQ就可以指定如何正确的路由到队列了。

交换器和队列实际上是多对多关系。就像关系数据库中的两张表。他们通过BindingKey做关联（多对多关系表）。在投递消息时，可以通过Exchange和RoutingKey（对应BindingKey）就可以找到相对应的队列。
信道：信道是建立在Connection之上的虚拟连接。当应用程序与RabbitMQ Broker建立TCP连接的时候，客户端紧接着可以创建一个AMQP信道（Channel），每个信道都会被指派一个唯一的ID。RabbitMQ处理的每条AMQP指令都是通过信道完成的。信道就像电缆里的光纤束。一条电缆内含有许多光纤束，允许所有的连接通过多条光纤束进行传输和接收。
## RabbitMQ的死信队列、延迟队列原理
死信消息

- 消息被消费方否定确认，使用channel.basicNack或者channel.basicReject，并且此时requeue属性被设置为false
- 消息在队列的存活时间超过设置的TTL时间
- 消息队列的消息数量已经超过最大队列长度

那么该消息将成为死信消息。如果配置了死信队列信息，那么该消息将会被丢进死信队列中，如果没有配置，则该消息将会被丢弃。
为每个需要使用死信的业务队列配置一个死信交换机，同一个项目的死信交换机可以共用一个，然后为每个业务队列分配一个单独的routeKey，死信队列只不过是绑定在死信交换机上的队列，死信交换机也不是什么特殊的交换机，只不过是用来接受死信的交换机，所以可以为任何类型【Direct、Fanout、Topic】

TTL：一条消息或者该队列中的所有消息的最大存活时间
如果一条消息设置了TTL属性或者进入了设置TTL属性的队列，那么这条消息如果在TTL设置的时间内没有被消费，则会成为死信。如果同时配置了队列的TTL和消息的TTL，那么较小的那个值将会被使用。
只需要消费者一直消费死信队列里的消息。
```
agruments.put("x-dead-letter-exchange","dlx.exchange");
channel.queueDeclare(queueName,true,false,false,agruments);
channel.queueBind(queueName,exchangeName,routingKey);
channel.exchangeDeclare("dlx.exchange","topic",true,false,null);
channel.queueDeclare("dlx.queue",true,false,false,null);
channel.queueBind("dlx.queue","dlx.exchange","#");
```
## RabbitMQ如何保证消息的可靠性传输

- 使用事务消息
- 使用消息确认机制

发送方确认：

- channel设置为confirm模式，则每条消息会被分配一个唯一id
- 消息投递成功，信道会发送ack给生产者，包含了id，回调ConfirmCallback接口
- 如果发生错误导致消息丢失，发生nack给生产者，回调ReturnCallback接口
- ack和nack只有一个触发，且只有一次，异步触发。可以继续发送消息

接收方确认：

- 声明队列时，指定noack=false，broker会等待消费者手动返回ack，才会删除消息，否则立刻删除
- broker的ack没有超时机制，只会判断链接是否断开，如果断开，消息会被重新发送
## RabbitMQ可以直连队列么
生产者和消费者使用相同的参数声明队列。重复声明不会改变队列
```java
//生产者
channel.queueDeclare(QUEUE_NAME,false,false,false,null);
//发送10条消息
for(int i=10;i>0;i--){
	String message = "helloworld";
    channel.basicPublish("",QUEUE_NAME,null,message.getBytes());
}

//消费者
channel.queueDeclare(QUEUE_NAME,false,false,false,null);
QueueingConsumer consumer = new QueueingConsumer(channel);
channel.basicConsume(QUEUE_NAME,true,consumer);
while(true){
	QueueingConsumer.Delivery delivery = consumer.nextDelivery();
    String message = new String(delivery.getBody());
    doWork(message);
}
```
```java
channel.queueDeclare(queue,durable,exclusive,autoDelete,arguments);

queue：队列名字
durable：队列持久化标志，true为持久化队列
exclusive：exclusive排他队列，仅对创建的链接可见、链接中的channel都可见，
	其他链接不能重复声明，链接关闭队列会被自动删除
autoDetele：自动删除，如果该队列没有任何订阅的消费者的话，该队列会被自动删除。
	这种队列适用于临时队列。
arguments：Map类型，队列参数设置
	x-message-ttl：数字，消息队列中消息的存活时间，超过会被删除
	x-expires：数字，队列自身的空闲存活时间，指定时间内没有被访问，就会被删除
	x-max-length和x-max-length-bytes：队列最大长度和空间，超过会删除老的数据
	x-dead-letter-exchange和x-dead-letter-routing-key：设置死信
	x-max-priority：队列支持的优先级别，需要生产者在发送消息时指定，消息按照优先级从高到底分发给消费者


channel.basicPublish(exchange,routingKey,mandatory,immediate,basicProperies,body);
exchange：交换机名
routingKey：路由键
mandatory：为true时，如果exchange根据自身类型和消息routeKey无法找到一个符合条件的queue，那么会调用
basic.return方法将消息返回给生产者，channel.addReturnListener添加一个监听器，
	当broker执行basic.return方法时，会回调handleReturn方法，这样就可以处理变为死信的消息了；设为false时，
	出现上述情形broker会直接将消息扔掉
immediate：3.0以前这个标志告诉服务器如果该消息关联的queue上有消费者，则马上将消息投递给它，
	如果所有queue都没有消费者，直接把消息返还给生产者，不用将消息入队列等待消费者了。3.0之后取消了该参数
basicProperties：消息的详细属性，优先级别、持久化、到期时间等，headers类型的exchange要用到的是其中的headers字段
body：消息实体，字节数组

QueueingConsumer：一个已经实现好了的Consumer，相当于自己实现Consumer接口，
	这是个比较安全快捷的方式。该类基于jdk的BlockingQueue实现，
	handleDelivery方法中将收到的消息封装成Delivery对象，
	并存放到BlockingQueue中，这相当于消费者本地存放了一个消息缓存队列。
	nextDelivery()方法底层调用的BlockingQueue的阻塞方法take()。

channel.basicConsume(queue,autoAck,consumer);
queue：队列名
autoAck：自动应答标志，true为自动应答
consumer：消费者对象，可以自己实现Consumer接口，建议使用QueueingConsumer。
	

```

## RabbitMQ如果确保消息发送和接收
发送方确认机制：
信道需要设置为confirm模式，则所有在信道上发布的消息都会分配一个唯一 ID。
一旦消息被投递到queue（可持久化的消息需要写入磁盘），信道会发送一个确认给生产者（包含消息唯一工D）。 
如果RabbitMQ发生内部错误从而导致消息丢失，会发送一条nack（未确认）消息给生产者。 
所有被发送的消息都将被confirm（即 ack）或者被nack一次。但是没有对消息被confirm 的快慢做任何保证，并且同一条消息不会既被confirm又被nack 。
发送方确认模式是异步的，生产者应用程序在等待确认的同时，可以继续发送消息。当确认消息到达生产者，生产者的回调方法会被触发。 
ConfirmCallback接口：只确认是否正确到达 Exchange 中，成功到达则回调。
ReturncaCallback接口：消息失败返回时回调。

接收方确认机制：
消费者在声明队列时，可以指定noAck参数，当noAck=false时，RabbitNQ会等待消费者显式发回ack信号后才从内存（或者磁盘，持久化消息）中移去消息。否则，消息被消费后会被立即删除。
消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作）。只有消费者确认了消息，RabbitMQ才能安全地把消息从队列中删除。
RabbitMQ不会为未ack的消息设置超时时间，它判断此消息是否需要重新投递给消费者的唯一依据是消费该消息的消费者连接是否已经断开。这么设计的原因是RabbitMQ允许消费者消费一条消息的时间可以很长。保证数据的最终一致性；
如果消费者返回ack之前断开了链接，RabbitMQ会重新分发给下一个订阅的消费者。(可能存在消息重复消费的隐患，需要去重)。
## RabbitMQ的镜像队列原理
GM负责消息的广播，所有的GM组成gm_group，形成链表结构，负责监听相邻节点的状态，以及传递消息到相邻节点，master的GM收到消息时代表消息同步完成
mirror_queue_master/slave负责消息的处理，操作blockingQueue，Queue负责AMQP协议（commit、rollback、ack等）
master处理读写
## RabbitMQ事务消息
通过对信道的设置实现

- channel.txSelect();	通知服务器开启事务模式；服务端会返回Tx.Select-Ok
- channel.basicPublish;	发送消息，可以是多条，可以是消费消息提交ack
- channel.txCommit();	提交事务
- channel.txRollback();	 回滚事务

消费者使用事务

- autoAck=false，手动提交ack，以事务提交或回滚为准
- autoAc=true，不支持事务，也就是说你即使在收到消息之后再回滚事务也是于事无补，队列已经把消息移除了

如果其中任意一个环节出现问题，就会抛出IoException异常，用户可以拦截异常进行事务回滚，或决定要不要重复消息。
事务消息会降低RabbitMQ的性能。
## RabbitMQ持久化机制

- 交换机持久化：exchange_declare创建交互机时通过参数指定
- 队列持久化：queue_declare创建队列时通过参数指定
- 消息持久化：new AMQPMessage创建消息时通过参数指定

append的方式写文件，会根据大小自动生成新的文件，RabbitMQ启动时会创建两个进程，一个负责持久化消息的存储，另一个负责非持久化消息的存储（内存不够时）。
消息存储时会在ets表中记录消息在文件中的映射以及相关信息（包括ID、偏移量、有效数据、左边文件、右边文件），消息读取时根据该信息到文件中读取、同时更新消息。
消息删除时只从ets删除，变为垃圾数据，当垃圾数据超过比例（默认50%），并且文件数达到3个，触发垃圾回收，锁定左右两个文件，整理左边文件有效数据、将右边文件有效数据写入到左边，更新文件信息，删除右边，完成合并。当一个文件额有用数据等于0时，删除该文件。

写入文件前先写buffer缓冲区，如果buffer已满，则写入文件（此时只是操作系统额页存）
每隔25ms刷一次磁盘，不管buffer满没满，都将buffer和页存中的数据落盘
每次消息写入后，如果没有后续写入请求，则直接刷盘
## 简述RabbitMQ的交换机类型
交换器分发会先找出绑定的队列，然后再判断routeKey，来决定是否将消息分发到某一个队列中
```java
// 在RabbitMQ中创建一个信道
Channel channel = connection.createChannel();
// 创建一个type为direct的交换器
channel.exchangeDeclare("exchangeName","direct");
// 创建一个队列
channel.queueDeclare("queueName");
// 绑定并设置路由键
channel.queueBind("queueName","exchangeName","zhangsan");
channel.queueBind("queueName","exchangeName","lisi");
channel.queueBind("queueName","exchangeName","wangwu");
```

- fanout：扇形交换机，不再判断routeKey
- direct：判断routeKey的规则是完全匹配模式，即发送消息时指定的routekey要等于绑定的routekey
- topic：判断routekey的规则是模糊匹配模式
- header：绑定队列与交换器的时候指定一个键值对，当交换器在分发消息的时候会先解开消息体里的headers数据，然后判断里面是否有所设置的键值对，如果发现匹配成功，才将消息分发到队列中；这种交换器类型在性能上相对来说较差，在实际工作中很少会用到
# RocketMQ消息中间件
## RocketMQ如何保证不丢消息
生产者：

- 同步阻塞的方式发送消息，加上失败重试机制，可能broker存储失败，可以通过查询确认
- 异步发送需要重写回调方法，检查发送结果
- ack机制，可能存储CommitLog，存储ConsumerQueue失败，此时对消费者不可见

broker：同步刷盘、集群模式下采用同步复制、会等待slave复制完成才会返回确认
消费者：

- offset手动提交，消息消费保证幂等
## RocketMQ事务消息原理
依赖于TransactionListener接口

- executeLocalTransaction方法会在发送消息后调用，用于执行本地事务，如果本地事务执行成功，RocketMQ再提交消息
- checkLocalTransaction用于对本地事务做检查，RocketMQ依赖此方法做补偿

通过两个内部的topic来实现对消息的两阶段支持，

- prepare：将消息（消息上带有事务标识）投递到一个名为RMS_SYS_TRANS_HALF_TOPIC的topic中，而不是投递到真正的topic中。
- commit/rollback：producer再通过TransactionListener的executeLocalTransaction方法执行本地事务，当producer的localTransaction处理成功或失败后，producer会向broker发送commit或rollback命令，如果是commit，则broker会将投递到RMQ_SYS_TRANS_HALF_TOPIC中的消息投递到真实的topic中，然后再投递一个表示删除的消息到RMQ_SYS_TRANS_OP_HALF_TOPIC中，表示当前事务已完成；如果是rollback，则没有投递到真实topic的过程，只需要投递表示删除的消息到RMQ_SYS_TRANS_OP_HALF_TOPIC。最后，消费者和消费普通的消息一样消费事务消息

第一阶段（prepare）失败：给应用返回发送消息失败
事务失败：发送回滚命令给broker，由broker执行消息的回滚
commit或rollback失败：由broker定时向producer发起事务检查，如果本地事务成功，则提交消息事务，否则回滚消息事务
事务状态的检查有两种情况

- commit/rollback：broker会执行相应的commit/rollback操作
- 如果是TRANSACTION_NOT_TYPE，则一段时间后会再次检查，当检查的次数超过上限（默认15次）则丢弃消息
## RocketMQ怎么实现顺序消息
默认是不能保证的，需要程序保证发送和消费的是同一个queue，多线程消费也无法保证
发送顺序：发送端自己业务逻辑保证先后，发往一个固定的queue，生产者可以在消息体上设置消息的顺序
发送者实现MessageQueueSelector接口，选择一个queue进行发送，也可使用RocketMQ提供的默认实现

- SelectMessageQueueByHash：按参数的hashcode与可选队列进行求余选择
- SelectMessageQueueByRandom：随机选择

mq：queue本身就是顺序追加写，只需保证一个队列统一时间只有一个consumer消费，通过加锁实现，consumer上的顺序消费有一个定时任务，每隔一定时间向broker发送请求延长锁定
消费端：

- pull模式：消费者需要自己维护需要拉取的queue，一次拉取的消息都是顺序的，需要消费端自己保证顺序消费
- push模式：消费实例实现自MQPushConsumer接口，提供注册监听的方法消费消息，registerMessageListener、重载方法
   - MessageListenerConcurrently：并行消费
   - MessageListenerOrderly：串行消费，consumer会把消息放入本地队列并加锁，定时任务保证锁的同步
## RocketMQ的底层实现原理
RocketMQ由NameServer集群、Producer集群、Consumer集群、Broker集群组成，消息生产和消费的大致原理如下：

- Broker在启动的时候向所有的NameServer注册，并保持长连接，每30s发送一次心跳
- Producer在发送消息的时候从NameServer获取Broker服务器地址，根据负载均衡算法选择一台服务器来发送消息
- Consumer消费消息的时候同样从NameServer获取Broker地址，然后主动拉取消息来消费
# Kafka消息中间件
## 简述Kafka架构设计

- Consumer Group：消费者组，消费者组内每个消费者负责消费不同分区的数据，提高消费能力。逻辑上的一个订阅者。
- Topic：可以理解为一个队列，Topic将消息分类，生产者和消费者面向的是同一个Topic。
- Partition：为了实现扩展性，提供并发能力，一个Topic以多个Partition的方式分布到多个Broker上，每个Partition是一个有序的队列。一个Topic的每个Partition都有若干个副本（Replica），一个Leader和若干个Follower。生产者发送数据的对象，以及消费者消费数据的对象，都是Leader。Follower负责实时从Leader中同步数据，保持和Leader数据的同步。Leader发生故障时，某个Follower还会成为新的Leader。
## Kafka的Pull和Push的优缺点

- pull表示消费者主动拉取，可以批量拉取，也可以单条拉取，所有pull可以由消费者自己控制，根据自己的消息处理能力来进行控制，但是消费者不能及时知道是否有消息，可能会拉到的消息为空。通过参数设置，consumer拉取数据为空或者没有达到一定数量时进行堵塞。
- push表示Broker主动给消费者推送消息，所以肯定是有消息时才会推送，但是消费者不能按自己的能力来消费消息，推过来多少消息，消费者就得消费多少消息，所以可能会造成网络堵塞，消费者压力大等问题
## Kafka高性能高吞吐的原因

- 磁盘顺序读写：保证了消息的堆积
   - 顺序读写，磁盘会预读，预读即在读取的起始位置连续读取多个页面，主要时间花费了传输时间，而这个时间两种读写可以认为是一样的
   - 随机读写，因为数据没有在一起，将预读浪费掉了。需要多次寻道和旋转延迟。而这个时间可能是传输时间的许多倍
- 零拷贝：避免CPU将数据从一块存储拷贝到另外一块存储的技术
   - 传统的数据复制
      - 1、读取磁盘文件数据到内核缓冲区
      - 2、将内核缓冲区的数据copy到用户缓冲区
      - 3、将用户缓冲区的数据copy到socket的发送缓冲区
      - 4、将socket发送缓冲区中的数据发送到网卡进行传输
   - 零拷贝
      - 磁盘文件 -> 内核空间读取缓冲区 -> 网卡接口 -> 消费者进程
- 分区分段和索引：Kafka的message消息实际上是分布式存储在一个一个小的segment中的，每次文件操作也是直接操作的segment。为了进一步的查询优化，Kafka又默认认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件。这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据操作的并行度
- 批量压缩：多条消息一起压缩，降低带宽
- 批量读写
- 直接操作page cache，而不是JVM，避免GC耗时及对象创建耗时，且读写速度更高，进程重启、缓存也不会丢失。
## kafka为什么吞吐量高
Kafka的生产者采用的是异步发送消息机制，当发送一条消息时，消息并没有发送到Broker而是缓存起来，然后直接向业务返回成功，当缓存的消息达到一定数量时再批量发送给Broker。这种做法减少了网络io，从而提高了消息发送的吞吐量，但是如果消息生产者宕机，会导致消息丢失，业务出错，所以理论上kafka利用此机制提高了性能却降低了可靠性。
## Kafka消息丢失的场景及解决方案
消息丢失场景

- ack=0;	不重试
   - producer发送消息完，不管结果了，如果发送失败也就丢失了。
- ack=1, leader crash
   - producer发送消息完，只等待lead写入成功就返回了，leader crash了，这时follower没来及同步，消息丢失。
- unclean.leader.election.enable 配置 true
   - 允许选举ISR以外的副本作为leader，会导致数据丢失，默认为false。producer发送异步消息完，只等待lead写入成功就返回了，leader crash了，这时ISR中没有follower，leader从OSR中选举，因为OSR中本来落后于leader造成消息丢失。
- 消费
   - 先commit再处理消息。如果在处理消息的时候异常了，但是offset已经提交了，这条消息对于该消费者来说就是丢失了，再也不会消费到了
- broker的刷盘
   - 减少刷盘间隔

解决方案

- 配置ack=all / -1,tries > 1,unclean.leader.election.enable:false
   - producer发送消息完，等待follower同步完再返回，如果异常则重试。副本的数量可能影响吞吐量。不允许选举ISR以外的副本作为leader。
- 配置：min.insync.replicas > 1
   - 副本指定必须确认写操作成功的最小副本数量。如果不能满足这个最小值，则生产者将引发一个异常（要么是NotEnoughReplicas，要么是NotEnoughReplicasAfterAppend）。min.insync.replicas和ack更大的持久性保证。确保如果大多数副本没有收到写操作，则生产者将引发异常。
- 失败的offset单独记录
   - producer发送消息，会自动重试，遇到不可恢复异常会抛出，这时可以捕获异常记录到数据库或缓存，进行单独处理。	
## Kafka消息高可靠解决方案

- 消息发送
   - ack:	0 不重试，1 lead写入成功就返回，all/-1 等待ISR同步完再返回
   - unclean.leader.electron.enable:false，禁止选举ISR以外的follower为leader
   - tries>1，重试次数
   - min.insync.replicas > 1，同步副本数，没满足该值前、不提供读写服务、写操作会异常
- 消费
   - 手动提交offset
   - broker：减少刷盘间隔
   - 事务消息

# 消息中间件
## 消息中间件对比

- ActiveMQ：JMS规范，支持事务，支持XA协议，没有生产大规模支撑场景，官方维护越来越少
- RabbitMQ：erlang语言开发、性能好、高并发、支持多种语言，社区、文档方面有优势，erlang语言不利于java程序员二次开发，依赖于开源社区的维护和升级，需要学习AMQP协议，学习成本相对较高，吞吐量单机万级
- Kafka：高性能，高可用，生产环境有大规模使用场景，单机容量有限（超过64个分区响应明显变长）、社区更新慢，吞吐量单机百万
- RocketMQ：java实现，方便二次开发、设计参考了kafka，高可用、高可靠，社区活跃度一般，支持语言较少，吞吐量单机十万
