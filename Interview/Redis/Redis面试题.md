## Redis常见面试题
### **Redis是单线程还是多线程**
`Redis6.0`版本之前的单线程指的是其网络IO和键值对读写是由一个线程完成的。
`Redis6.0`引入的多线程指的是网络请求过程中采用了多线程，而键值对读写命令仍然是单线程处理的，所以`Redis`依然是并发安全的。也就是只有网络请求模块和数据操作模块是单线程的，而其它的持久化、集群数据同步等，其实是由额外的线程执行的。
### **Redis单线程为什么还能这么快**

- 命令执行基于内存操作，一条命令在内存里操作的时间是几十纳秒
- 命令执行是单线程操作，没有线程切换开销
- 基于IO多路复用机制提升`Redis`的I/O利用率
- 高效的数据存储结构：全局hash表以及多种高效数据结构，比如：跳表、压缩列表、链表等等
### **Redis多线程使用**
`Redis6.0`的多线程默认是禁用的，只使用主线程。如需开启需要修改`redis.conf`配置文件：
```xml
io-threads-do-reads yes
```
**Redis多线程开启时，线程数如何设置**
开启多线程后，还需要设置线程数，否则是不生效的。同样修改`redis.conf`配置文件
```xml
io-threads 4
```
关于线程数的设置，官方有一个建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程，线程数一定要小于机器核数。还需要注意的是，线程数并不是越大越好，官方认为超过了8个基本就没什么意义了。
**Redis多线程的实现机制**

- 1、主线程负责接收建立连接请求，获取`socket`放入全局等待读处理队列
- 2、主线程处理完读事件之后，通过`RR(Round Robin)` 将这些连接分配给这些`IO`线程
- 3、主线程阻塞等待`IO`线程读取`socket`完毕
- 4、主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行
- 5、主线程阻塞等待`IO`线程将数据回写`socket`完毕
- 6、解除绑定，清空等待队列

该设计有如下特点：

- `IO`线程要么同时在读 `socket`，要么同时在写，不会同时读或写
- `IO`线程只负责读写`socket`解析命令，不负责命令处理

**Redis线程中理解IO多路复用**
多路指的是多个`socket`连接，复用指的是复用一个线程。多路复用主要有三种技术：`select`，`poll`，`epoll`。`epoll`是最新的也是目前最好的多路复用技术。
采用多路`I/O`复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且`Redis`在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了`Redis`具有很高的吞吐量。
### Redis底层数据是如何用跳表来存储的
跳表：将有序链表改造为支持近似“折半查找”算法，可以进行快速的插入、删除、查找操作。
### Redis Key过期了为什么内存没释放
你在使用Redis时，肯定经常使用`SET`命令
`SET`除了可以设置`key-value` 之外，还可以设置`key` 的过期时间
```bash
> SET a test EX 120
OK
> TTL a
(integer) 117
```
此时如果你想修改`key` 的值，但只是单纯地使用`SET`命令，而没有加上过期时间的参数，那这个`key`的过期时间将会擦除
```bash
> SET a test1
OK
> TTL a //key永远不过期了
(integer) -1
```
导致这个问题的原因在于：`SET`命令如果不设置过期时间，那么`Redis`会自动擦除这个`key`的过期时间，如果你发现`Redis`的内存持续增长，而且很多`key`原先设置了过期时间，后来发现过期时间丢失了，很有可能是因为这个原因导致的。
这时你的`Redis`中就会存在大量不过期的`key`，消耗过多的内存资源。
所以你在使用`SET`命令时，如果刚开始就设置了过期时间，那么之后修改这个`key`，也务必要加上过期时间的参数，避免过期时间丢失问题。
`Redis`对于过期`key`的处理一般有惰性删除和定时删除两种策略

- 惰性删除：当读/写一个已经过期的`key`时，会触发惰性删除策略，判断`key`是否过期，如果过期了直接删除这个`key`
- 定时删除：由于惰性删除策略无法保证冷数据被计时删掉，所以`Redis`会定期（默认每100ms）主动淘汰一批已过期的`key`，这里的一批只是部分过期`key`，所以可能会出现部分`key`已经过期但还没有被清理掉的情况，导致内存并没有被释放。
### Redis Key没设置过期时间为什么被Redis主动删除了
当`Redis`已用内存超过了`maxmemory`限定时，触发主动清理策略。
主动清理策略在`Redis 4.0`之前一共实现了6种内存淘汰策略，在4.0之后，又增加了2种策略，总共8种。

-  针对设置了过期时间的`key`做处理 
   - `volatile-ttl` 在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先删除
   - `volatile-random` 在设置了过期时间的键值对中，进行随机删除
   - `volatile-lru` 使用LRU算法筛选设置了过期时间的键值对删除
   - `volatile-lfu` 会使用LFU算法筛选设置了过期时间的键值对删除
-  针对所有的key做处理 
   - `allkeys-random` 从所有键值对中随机选择并删除数据
   - `allkeys-lru` 使用LRU算法在所有数据中进行筛选删除
   - `allkeys-lfu` 使用LFU算法在所有数据中进行筛选删除
-  不处理 
   - `noeviction` 不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”`(error) OOM command not allowed when used memory`”，此时`Redis`只响应读操作。

_注意_

- `LRU算法`（Least Recently Used，最近最少使用）：淘汰很久没被访问过的数据，以最近一次访问时间作为参考
- `LFU算法`（Least Frequently Used，最不经常使用）：淘汰最近一段时间被访问次数最少的数据，以次数作为参考

绝大多数情况我们都是使用`LRU策略`，当存在大量热点缓存数据时，`LFU`可能更好点。 
### Redis节省内存
**控制 key 的长度**
最简单直接的内存优化，就是控制 `key`的长度。
在开发业务时，你需要提前预估整个 `Redis`中写入 `key`的数量，如果 `key`数量达到了百万级别，那么，过长的 `key`名也会占用过多的内存空间。所以，你需要保证 `key`简单、清晰的前提下，尽可能把 `key`定义得短一些。
**避免存储 bigkey**
除了控制 `key`的长度之外，你同样需要关注 `value`的大小，如果大量存储 `bigkey`，也会导致 `Redis`内存增长过快。
除此之外，客户端在读写`bigkey`时，还有产生性能问题。
所以，你要避免在 `Redis`中存储 `bigkey`：

- `String`：大小控制在 `10KB`以下
- `List/Hash/Set/ZSet`：元素数量控制在 1 万以下

**实例设置 maxmemory + 淘汰策略**
虽然你的`Redis key`都设置了过期时间，但如果你的业务应用写入量很大，并且过期时间设置得比较久，那么短期间内`Redis`的内存依旧会快速增长。如果不控制`Redis`的内存上限，也会导致使用过多的内存资源。对于这种场景，你需要提前预估业务数据量，然后给这个实例设置 `maxmemory`控制实例的内存上限，这样可以避免 `Redis`的内存持续膨胀。
配置了`maxmemory`，此时你还要设置数据淘汰策略，而淘汰策略如何选择，你需要结合你的业务特点来决定：

- `volatile-lru / allkeys-lru`：优先保留最近访问过的数据
- `volatile-lfu / allkeys-lfu`：优先保留访问次数最频繁的数据（4.0+版本支持）
- `volatile-ttl` ：优先淘汰即将过期的数据
- `volatile-random / allkeys-random`：随机淘汰数据
### Redis集群数据hash分片算法
`Redis Cluster` 将所有数据划分为16384个`slots`（槽位），每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。
当`Redis Cluster`的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。这样当客户端要查找某个`key`时，可以根据槽位定位算法定位到目标节点。
**槽位定位算法**
`Cluster`默认会对`key`值使用`crc16`算法进行`hash`得到一个整数值，然后用这个整数值对`16384`进行取模来得到具体槽位。
`HASH_SLOT = CRC16(key) mod 16384`
再根据槽位值和`Redis`节点的对应关系就可以定位到`key`具体是落在哪个`Redis`节点上的。
### 一次线上事故，Redis主从切换导致了缓存雪崩
我们假设，`slave`的机器时钟比`master`走得快很多。
此时，`Redis master`里设置了过期时间的`key`，从`slave`角度来看，可能会有很多在`master`里没过期的数据其实已经过期了。
如果此时操作主从切换，把`slave`提升为新的`master`。
它成为`master`后，就会开始大量清理过期的`key`，此时就会导致以下结果：

- `master`大量清理过期`key`，主线程可能会发生阻塞，无法及时处理客户端请求
- `Redis`中数据大量过期，引发缓存雪崩

当`master`与`slave`机器时钟严重不一致时，对业务的影响非常大。
所以，我们一定要保证主从库的机器时钟一致性，避免发生这些问题。
### RDB和AOF机制
`RDB Redis DataBase`
在指定的时间间隔内将内存中数据集快照写入磁盘，实际操作过程是`fork`一个子进程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。
手动触发

- `save`命令，使`Redis`处于阻塞状态，直到`RDB`持久化完成，才会响应其他客户端发来的命令，所以在生产环境一定要慎用。
- `bgsave`命令，`fork`出一个子进程进行持久化，主进程只在`fork`过程中有短暂的阻塞，子进程创建之后，主进程就可以响应客户端请求了

自动触发

- `save m n` 在m秒内，如果有n个键发生改变，则自动触发持久化，通过`bgsave`执行，如果设置多个，只要满足其一就会触发，配置文件有默认配置
- `flushall`  用于清空`redis`所有的数据库，`flushdb`清空`Redis`所在的库数据（默认是0号数据库），会清空`RDB`文件，同时也会生成`dump.rdb`，内容为空
- 主从同步 全量同步时会自动触发`bgsave`命令，生成`rdb`发送给从节点

优点
1、整个`Redis`数据库将只包含一个文件`dump.db`，方便持久化
2、容灾性好，方便备份
3、性能最大化，`fork`子进程来完成写操作，让主进程继续处理命令，所以是`IO`最大化。使用单独子进程来进行持久化，主进程不会进行任何`IO`操作，保证了`redis`的高性能
缺点
1、数据安全性低。`RDB`是间隔一段时间进行持久化，如果持久化之间`redis`发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候
2、由于`RDB`是通过`fork`子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致整个服务器停止服务几百毫秒，甚至是1秒钟
`AOF Append Only File`
以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。
优点
1、数据安全，`Reids`中提供了三种同步策略，即每秒同步、每修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现宕机现象，那么这一秒之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即每次发生的数据变化都会被立即记录到磁盘中，最多丢一条。不同步是由操作系统控制，可能丢失较多数据。
2、通过`append`模式写文件，即使中途服务器宕机也不会破坏已经存在的内容，可以通过`redis-check-aof`工具解决数据一致性问题
3、`AOF`机制的`rewrite`模式。定期对`AOF`文件进行重写，以达到压缩的目的。
缺点
1、`AOF`文件比`RDB`文件大，且恢复速度慢。
2、数据集大的时候，比`rdb`启动效率低。
3、运行效率没有`RDB`高。

- `AOF`文件比`RDB`更新频率高，优先使用`AOF`还原数据
- `AOF`比`RDB`更安全也更大
- `RDB`性能比`AOF`好
- 如果两个都配了优先加载`AOF`
### 线上Redis持久化策略一般如何设置
如何对性能要求较高，在`Master`最好不要做持久化，可以在某个`Slave`开启`AOF`备份数据，策略设置为每秒同步一次即可。
### Redis线上数据如何备份

- 写`crontab`定时调度脚本，每小时都`copy`一份`rdb`或`aof`文件到另外一台机器中去，保留最近48小时的备份
- 每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份
- 每次`copy`备份的时候，都把太旧的备份给删了
### Redis主从复制风暴
如果`Redis`主节点有很多从节点，在某个时刻如果所有从节点都同时连接主节点，那么主节点会同时把内存快照`RDB`发给多个从节点，这样会导致`Redis`主节点压力非常大，这就是所谓的`Redis`主从复制风暴问题。
### Redis集群策略

1. 主从模式：这种模式比较简单，主库可以读写，并且会和从库进行数据同步，这种模式下，客户端可以直接连主库或某个从库，但是主库或从库宕机后，客户端需要手动修改IP，另外，这种模式也比较难以扩容，整个集群所能存储的数据受到某台机器的内存容量，所以不可能支持特大数据量
2. 哨兵模式 ：这种模式在主从的基础上新增了哨兵节点，但主库节点宕机后，哨兵会发现主库节点宕机，然后在从库选择一个库作为新的主库，另外哨兵也可以做集群，从而保证某一个哨兵节点宕机后，还有其他哨兵节点可以继续工作，这种模式可以比较好的保证Redis集群的高可用，但是仍然不能很好解决Redis容量上的问题
3. Cluster模式 ：Cluster模式是用得比较多的模式，他支持多主多从，这种模式会按照key进行槽位的分配，可以使得不同的key分散到不同的节点，利用这种模式可以使得整个集群支持更大得数据容量，同时每个主节点可以拥有自己多个从节点，如果该节点宕机，会从他的从节点中选举一个新的主节点
### Redis集群为什么至少需要三个master节点
因为新`master`的选举需要大于半数的集群`master`节点同意才能选举成功，如果只有两个`master`节点，当其中一个挂了，是达不到选举新`master`的条件的。
### Redis集群支持批量操作命令吗
对于类似`mset`、`mget`这样的多个`key`的原生批量操作命令，`redis`集群只支持所有`key`落在同一个`slot`的情况，如果有多个`key`一定要用`mset`命令在`redis`集群上操作，则可以在`key`的前面加上`{XXX}`，这样参数数据分片hash计算的只会是大括号里的值，这样能确保不同的`key`能落到同一个`slot`里去，
```bash
	mset {user1}:1:name zhuge {user1}:1:age 18
```
假设`name`和`age`计算的`hash slot`值不一样，但是这条命令在集群下执行，`redis`只会用大括号里`user1`做`hash slot`计算，所以算出来的slot值肯定相同，但是都能落在同一`slot`。
### Lua脚本能在Redis集群里执行吗
`Redis`官方规定`Lua`脚本如果想在`Redis`集群里执行，需要`Lua`脚本里操作的所有`Redis Key`落在集群的同一个节点上，这种的话我们可以给`Lua`脚本的`key`前面加一个相同的`hash tag`，就是`{XXX}`，这样就能保证Lua脚本里所有`key`落在相同的节点上。
### Redis分布式锁底层是如何实现的的

1. 首先利用`setnx`来保证：如果`key`不存在才能获取到锁，如果`key`存在，则获取不到锁
2. 然后还要利用`lua`脚本来保证多个`redis`操作的原子性
3. 同时还要考虑到锁过期，所以需要额外的一个看门狗定时任务来监听锁是否需要续约
4. 同时还要考虑到`redis`节点挂掉后的情况，所以需要采用红锁的方式来同时向`N/2+1`个节点申请锁，都申请到了才证明获取锁成功，这样就算其中某个`redis`节点挂掉了，锁也不能被其他客户端获取到
### Redis主从复制的核心原理
`Redis`的主从复制是提高`Redis`的可靠性的有效措施，主从复制的流程如下：

1. 集群启动时，主从库间会先建立连接，为全量复制做准备
2. 主库将所有数据同步给从库，从库收到数据后，在本地完成数据加载，在这个过程依赖于内存快照`RDB`
3. 在主库将数据同步给从库的过程中，主库不会阻塞，仍然可以正常接收请求。否则，`redis`的服务就被中断了。但是这些请求中的写操作并没有记录到刚刚生成的`RDB`文件中。为了保证主从库的数据一致性，主库会在内存中用专门的`replication buffer`，记录`RDB`文件生成收到的所有写操作。
4. 最后也就是第三个阶段，主库会把第二阶段执行过程中新收到的写命令，再发送给从库。具体操作是，当主库完成`RDB`文件发送后，就会把此时`replication buffer`中修改操作发送给从库，从库再执行这些操作。这样一来，主从库就实现同步了。
5. 后续主库和从库都可以处理客户端读操作，写操作只能交给主库处理，主库接收到写操作后，还会将写操作发送给从库，实现增量同步。
### Redis和MySQL如何保证数据一致

1. 先更新`MySQL`，再更新`Redis`，如果更新`Redis`失败，可能仍然不一致
2. 先删除`Redis`缓存数据，再更新`MySQL`，再次查询的时候再将数据添加到缓存中，这种方案能解决1方案的问题，但是在高并发下性能较低，而且仍然会出现数据不一致的问题，比如线程1删除了`Redis`缓存数据，正在更新`MySQL`，此时另外一个查询在查询，那么就会把`MySQL`中老数据又查到`Redis`中
3. 延时双删，步骤是：先删除`Redis`缓存数据，再更新`MySQL`，延迟几百毫秒再删除Redis缓存数据，这样就算在更新`MySQL`时，有其他线程读了`MySQL`，把老数据读到了`Redis`中，那么也会被删除掉，从而把数据保持一致。

**先更新数据库，再更新缓存**
这么做的问题是：当有 2 个请求同时更新数据，那么如果不使用分布式锁，将无法控制最后缓存的值到底是多少。也就是并发写的时候有问题。
**先删缓存，再更新数据库**
这么做的问题：如果在删除缓存后，有客户端读数据，将可能读到旧数据，并有可能设置到缓存中，导致缓存中的数据一直是老数据。

- 使用“双删”，即删更删，最后一步的删除作为异步操作，就是防止有客户端读取的时候设置了旧值。
- 使用队列，当这个`key`不存在时，将其放入队列，串行执行，必须等到更新数据库完毕才能读取数据。

**先更新数据库，再删除缓存**
如果先更新数据库，再删除缓存，那么就会出现更新数据库之前有瞬间数据不是很及时。同时，如果在更新之前，缓存刚好失效了，读客户端有可能读到旧值，然后在写客户端删除结束后再次设置了旧值，非常巧合的情况。

有 2 个前提条件：**缓存在写之前的时候失效，同时，在写客户度删除操作结束后，放置旧数据 —— 也就是读比写慢。 设置有的写操作还会锁表。**
所以，这个很难出现，但是如果出现了怎么办？使用双删！！！记录更新期间有没有客户端读数据库，如果有，在更新完数据库之后，执行延迟删除。还有一种可能，如果执行更新数据库，准备执行删除缓存时，服务挂了，执行删除失败怎么办？可以通过订阅数据库的`binlog`来删除。
### Redis的数据结构及使用场景

1. 字符串 ： 可以用来做最简单的数据缓存，可以缓存某个简单的字符串，也可以缓存某个`json`字符串，`Redis`分布式锁的实现就利用了这种数据结构，还包括可以实现计数器、`Session`共享、分布式ID
2. 哈希表 ：可以用来存储一些`key-value`对，更适合用来存储对象
3. 列表 ：`Redis`的列表通过命令的组合，既可以当做栈，也可以当作队列来使用，用来缓存类似公众号、微博等消息流数据
4. 集合 ：和列表类似，也可以存储多个元素，但是不能重复，集合可以进行交集、并集、差集等操作，从而可以实现类似，我和某人共同关注的人、朋友圈点赞等功能
5. 有序集合 ：集合是无序的，有序集合可以设置顺序，可以用来实现排行榜功能
### 常见的缓存淘汰算法

- FIFO（`First In First Out`，先进先出），根据缓存被存储的时间，离当前最远的数据优先被淘汰
- LRU（`Least Recently Used`，最近最少使用），根据最近被使用的时间，离当前最远的数据优先淘汰
- LFU（`Least Frequently Used`，最不经常使用），在一段时间内，缓存数据被使用次数最少的会被淘汰
### 分布式系统中常用的缓存方案

- 客户端缓存：页面和浏览器缓存，APP缓存，H5缓存，localStorage和sessionStorage
- CDN缓存：内存存储，数据的缓存，内容分发：负载均衡
- Nginx缓存：静态资源
- 服务端缓存：本地缓存，外部缓存
- 数据库缓存：持久层缓存（mybatis、hibernate多级缓存）、mysql查询缓存
- 操作系统缓存：Page Cache、Buffer Cache
### 缓存雪崩
缓存雪崩是指缓存同一时间大面积的失效，所以后面的请求都会落到数据库上，造成数据库短时间内承受大量请求而崩掉。
解决方案

- 缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。
- 给每个缓存数据增加相应的缓存标记，记录缓存是否失效，如果缓存标记失效，则更新数据缓存
- 缓存预热
- 互斥锁
### 缓存穿透
缓存穿透是指缓存和数据库中都没有的数据，导致所有的请求都落到数据库上，造成数据库短时间内承受大量请求而崩掉。
解决方案

- 接口层增加校验，若用户鉴权校验，id做基础校验，id≤0的直接拦截
- 从缓存不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击
- 采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力
### 缓存击穿
缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力。和缓存雪崩不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，很多数据都查不到从而查数据库
解决方案

- 设置热点数据永远不过期
- 加互斥锁‘
## Redis数据类型
### STRING
STRING是最基本的数据类型，且是二进制安全的，一个STRING类型的值最多存储512M字节内容。 其中STRING可以包括字符串、整数或者浮点数。
1、常用操作
```
SET key value 
设置指定 key 的值

GET key 
获取指定 key 的值。

SETEX key seconds value
将值 value 关联到 key ，并将 key 的过期时间设为 seconds (以秒为单位)。

SETNX key value
只有在 key 不存在时设置 key 的值。

INCR key
将 key 中储存的数字值增一。

DECR key
将 key 中储存的数字值减一。
```
2、实际操作
```
127.0.0.1:6379> set hello world
OK
127.0.0.1:6379> get hello
"world"

127.0.0.1:6379> setnx hello redis
(integer) 0
127.0.0.1:6379> get hello
"world"
127.0.0.1:6379> setnx hello1 redis
(integer) 1
127.0.0.1:6379> get hello1
"redis"

127.0.0.1:6379> set num 12
OK
127.0.0.1:6379> incr num
(integer) 13
127.0.0.1:6379> decr num
(integer) 12
127.0.0.1:6379>
```
STRING类型一般用于复杂的字符串类型的缓存存储，共享Session服务器，计数器或限速器等等。
### LIST
LIST是字符串列表，按照插入顺序排序，一个LIST类型最多可以包含`2^32 - 1`个元素。
1、常用操作
```
LPUSH key value1 [value2] 
将一个或多个值插入到列表头部

LPOP key 
移出并获取列表的第一个元素

LLEN key 
获取列表长度

LPUSHX key value 
将一个值插入到已存在的列表头部

LRANGE key start stop 
获取列表指定范围内的元素

RPOP key 
移除列表的最后一个元素，返回值为移除的元素。

RPUSH key value1 [value2] 
在列表中添加一个或多个值
```
2、实际操作
```
127.0.0.1:6379> lpush mylist A1
(integer) 1
127.0.0.1:6379> lpush mylist A2
(integer) 2

127.0.0.1:6379> llen mylist
(integer) 2

127.0.0.1:6379> lrange mylist 0 -1
1) "A2"
2) "A1"

127.0.0.1:6379> rpush mylist B1
(integer) 3

# 0 表示第一个元素 -1 表示最后一个元素
127.0.0.1:6379> lrange mylist 0 -1
1) "A2"
2) "A1"
3) "B1"

127.0.0.1:6379> lpop mylist
"A2"
127.0.0.1:6379>
```
LIST一般可以做简单的消息队列功能，lrange还可以做基于Redis的分页功能。其中`LPUSH+LPOP`可实现栈，`LPUSH+RPOP`可实现队列，`LPUSH+LTRIM`可实现有限队列。
### HASH
HASH是一个STRING类型的键值对的映射，所以HASH特别适合存储对象。每个HASH可以存储`2^32 - 1`键值对。
1、常用操作
```
HMSET key field1 value1 [field2 value2 ] 
同时将多个 field-value (域-值)对设置到哈希表 key 中。

HSET key field value 
将哈希表 key 中的字段 field 的值设为 value 。

HMGET key field1 [field2] 
获取所有给定字段的值

HEXISTS key field 
查看哈希表 key 中，指定的字段是否存在。

HDEL key field1 [field2] 
删除一个或多个哈希表字段

HGET key field 
获取存储在哈希表中指定字段的值。

HGETALL key 
获取在哈希表中指定 key 的所有字段和值

HKEYS key 
获取所有哈希表中的字段

HLEN key 
获取哈希表中字段的数量

HSETNX key field value 
只有在字段 field 不存在时，设置哈希表字段的值。

HVALS key 
获取哈希表中所有值

HSCAN key cursor [MATCH pattern] [COUNT count] 
迭代哈希表中的键值对。
```
2、实际操作
```
127.0.0.1:6379> hmset AA age 12 sex fmale
OK
127.0.0.1:6379> hmset BB age 13 sex male
OK
127.0.0.1:6379> hget AA age
"12"
127.0.0.1:6379> hkeys AA
1) "age"
2) "sex"
127.0.0.1:6379> hgetall AA
1) "age"
2) "12"
3) "sex"
4) "fmale"
127.0.0.1:6379> hlen AA
(integer) 2
127.0.0.1:6379>
```
HASH一般用于存放结构化的数据对象。
### SET
SET是STRING类型的无序集合，集合的元素是唯一，即集合中不会出现重复的元素。每个SET可以存储`2^32 - 1`元素。
SET的添加、删除的复杂度是`O(1)`。
1、常用操作
```
SADD key member1 [member2] 
向集合添加一个或多个成员

SCARD key 
获取集合的成员数

SDIFFSTORE destination key1 [key2] 
返回给定所有集合的差集并存储在 destination 中

SINTERSTORE destination key1 [key2] 
返回给定所有集合的交集并存储在 destination 中

SISMEMBER key member 
判断 member 元素是否是集合 key 的成员

SMEMBERS key 
返回集合中的所有成员

SMOVE source destination member 
将 member 元素从 source 集合移动到 destination 集合

SPOP key 
移除并返回集合中的一个随机元素

SRANDMEMBER key [count] 
返回集合中一个或多个随机数

SREM key member1 [member2] 
移除集合中一个或多个成员

SUNIONSTORE destination key1 [key2] 
所有给定集合的并集存储在 destination 集合中

SSCAN key cursor [MATCH pattern] [COUNT count] 
迭代集合中的元素
```
2、实际操作
```
127.0.0.1:6379> sadd myset AA
(integer) 1
127.0.0.1:6379> sadd myset BB
(integer) 1
127.0.0.1:6379> scard myset
(integer) 2
127.0.0.1:6379> smembers myset
1) "BB"
2) "AA"
127.0.0.1:6379> sscan myset 0 match * count 1
1) "1"
2) 1) "BB"
   2) "AA"
127.0.0.1:6379> sadd myset CC DD
(integer) 2
127.0.0.1:6379> smembers myset
1) "CC"
2) "BB"
3) "AA"
4) "DD"
127.0.0.1:6379> sscan myset 0 match * count 1
1) "2"
2) 1) "CC"
127.0.0.1:6379>
```
SET的不重复元素特点可以做全局去重，共同类型，共同喜好等功能。
### ZSET
ZSET和SET一样也是STRING类型元素的集合,且不允许重复的元素。不同的是每个元素都会关联一个double类型的分数。Redis正是通过这个分数来为集合中的成员进行从小到大的排序。每个SET可以存储`2^32 - 1`元素。
ZSET的添加、删除和更新元素的复杂度是`O(log(N))`。
1、常用操作
```
ZADD key score1 member1 [score2 member2] 
向有序集合添加一个或多个成员，或者更新已存在成员的分数

ZCARD key 
获取有序集合的成员数

ZCOUNT key min max 
计算在有序集合中指定区间分数的成员数

ZINTERSTORE destination numkeys key [key ...] 
计算给定的一个或多个有序集的交集并将结果集存储在新的有序集合 key 中

ZLEXCOUNT key min max 
在有序集合中计算指定字典区间内成员数量

ZRANGE key start stop [WITHSCORES] 
通过索引区间返回有序集合指定区间内的成员

ZREM key member [member ...] 
移除有序集合中的一个或多个成员

ZSCORE key member 
返回有序集中，成员的分数值

ZREVRANK key member 
返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序

ZREVRANGE key start stop [WITHSCORES] 
返回有序集中指定区间内的成员，通过索引，分数从高到低

ZREVRANGEBYSCORE key max min [WITHSCORES] 
返回有序集中指定分数区间内的成员，分数从高到低排序

ZUNIONSTORE destination numkeys key [key ...] 
计算给定的一个或多个有序集的并集，并存储在新的 key 中

ZSCAN key cursor [MATCH pattern] [COUNT count] 
迭代有序集合中的元素（包括元素成员和元素分值）
```
2、实际操作
```
127.0.0.1:6379> zadd myzset 13 AA
(integer) 1
127.0.0.1:6379> zadd myzset 14 BB
(integer) 1
127.0.0.1:6379> zadd myzset 12 CC
(integer) 1
127.0.0.1:6379> zcard myzset
(integer) 3
127.0.0.1:6379> zscore myzset AA
"13"
127.0.0.1:6379> zrange myzset 0 -1 withscores
1) "CC"
2) "12"
3) "AA"
4) "13"
5) "BB"
6) "14"
127.0.0.1:6379>
```
ZSET集合中的元素不重复，且按照score排列，可以做排行榜应用，执行任务权重，范围查找等功能。
